{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"clearfix\" style=\"padding: 10px; padding-left: 0px\">\n",
    "<h1 style=\"color:rgb(150,0,0);text-align:center\">  Notebook C : Emerging doc detection</h1>\n",
    "<h1 style=\"color:rgb(150,0,0) ;text-align:center\">  Began 21 May 2020</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,150,0);text-align:left\">  Intro</h1>\n",
    "<br/>\n",
    "<br/>\n",
    "This notebook is made for testing whether a new document belongs to a previous cluster or is a new type of doc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,0,200);text-align:left\">  Compare a new document to our clusters</h1>\n",
    "<br/>\n",
    "<br/>\n",
    "To do so we want to embed a new document and compare it vector representation to previous clusters. We have to set a similarity threshold while comparing the new vector to every centroids. This test is our way to detect emerging topics or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a specific report\n",
    "# process it\n",
    "# turn it to a list of tokens\n",
    "# generate a vector for this new report with word vectors averaging\n",
    "# compare it to centroids\n",
    "# say if it is an emerging topic according to a given threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) loading labels and centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(labels_filename):\n",
    "    \n",
    "    file = open(labels_filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    for line in lines:\n",
    "        label = int(line)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_centroids(centroids_filename):\n",
    "    \n",
    "    file = open(centroids_filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    centroids = []\n",
    "    \n",
    "    for line in lines:\n",
    "        \n",
    "        centroid = line\n",
    "        centroid = centroid.split(' ')\n",
    "        centroid.remove('\\n')\n",
    "        centroid = [float(e) for e in centroid]\n",
    "        centroids.append(centroid)\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, centroids = load_labels('labels_57_100d_5e_3000c.txt'), load_centroids('centroids_57_100d_5e_3000c.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b1) loading a new report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_report(doc_vectors_filename, report_number):\n",
    "    \n",
    "    file = open(doc_vectors_filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    doc_vector = lines[report_number]\n",
    "    doc_vector = doc_vector.split(' ')\n",
    "    doc_vector = [float(e) for e in doc_vector]\n",
    "    \n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector = load_new_report('w2v_doc_vectors_801_100d_5e.txt', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b2) loading a report from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_old_report(doc_vectors_filename, report_number):\n",
    "    \n",
    "    file = open(doc_vectors_filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    doc_vector = lines[report_number]\n",
    "    doc_vector = doc_vector.split(' ')\n",
    "    doc_vector = [float(e) for e in doc_vector]\n",
    "    \n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector = load_old_report('w2v_doc_vectors_57_100d_5e.txt', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) maximum similarity score with previous clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare it to centroids and get the label of closest cluster\n",
    "\n",
    "def max_cluster_similarity(centroids, doc_vector):\n",
    "\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    sim_scores=[]\n",
    "\n",
    "    for centroid in centroids:\n",
    "        sim_score = cosine_similarity([doc_vector], [centroid])[0][0]\n",
    "        sim_scores.append(sim_score)\n",
    "\n",
    "    max_score = max(sim_scores) # distance à comparer avec la distance max au sein du cluster\n",
    "    #cluster_number=sim_scores.index(max_score) # numéro du cluster le plus proche\n",
    "    \n",
    "    return (max_score) #, cluster_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = get_number_closest_cluster(centroids, doc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9705317703592524\n",
      "503\n"
     ]
    }
   ],
   "source": [
    "print(max_score)\n",
    "#print(cluster_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) test if new doc vector belongs to an old cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_vectors(reports_filename, labels_filename, centroids_filename, doc_vectors_filename):\n",
    "    \n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(reports_filename)\n",
    "    n = len(data)\n",
    "    \n",
    "    labels, centroids = load_labels(labels_filename), load_centroids(centroids_filename)\n",
    "    \n",
    "    file = open(doc_vectors_filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    #scores = []\n",
    "    #possible_clusters = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        doc_vector = lines[i]\n",
    "        doc_vector = doc_vector.split(' ')\n",
    "        doc_vector = [float(e) for e in doc_vector]    \n",
    "        #doc_vector = load_new_report(doc_vectors_filename, i)\n",
    "        max_score = max_cluster_similarity(centroids, doc_vector)\n",
    "        #scores.append(max_score)\n",
    "        #possible_clusters.append(cluster_number)\n",
    "        if max_score < 0.75 :\n",
    "            print(i)\n",
    "            print(max_score)\n",
    "            print(data['reports'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "0.7422715564197216\n",
      "a pilot reports the fmc database in his aircraft incorrectly identified jvl airport at the off field vor site and the jvl vor at the airport s physical location  . database mismatcherror from collins showing jvl vor at airport and jvl airport at vor causing us to turn about 8 nm early on airway  . controller notified us of situation  . callback conversation with rptr revealed the following info  the reporter stated that the vor and airport are swapped in the database  . correcting the error simply requires moving the airport to the vor s location and the vor to the airport s location  . \n",
      "187\n",
      "0.6243032198124792\n",
      "md80 captain is incapacitated for period of 30 seconds to two minutes  . captain was incapacitated for a period from 30 seconds to 2 mins  . long enough to summon a flight attendant  . eyes were opened but was unresponsive  . captain returned to normal state within a few mins  . flight continued uneventfully  . landed at zzz  . \n",
      "371\n",
      "0.7356701101462533\n",
      "b737800 captain discusses disruption to normal cockpit duties by intrusive raas announcements  . taking runway 16l at sea the raas announcement interfered with the takeoff checklist with the takeoff checklist  necessitating its repetition  . raas also interfered with hearing tower calls to other aircraft  thus reducing flight crew situational awareness  . get raas off our aircraft before it causes an incident or accident  . \n"
     ]
    }
   ],
   "source": [
    "test_new_vectors('reports_801.csv', 'labels_57_100d_5e_3000c.txt', 'centroids_57_100d_5e_3000c.txt', 'w2v_doc_vectors_801_100d_5e.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
